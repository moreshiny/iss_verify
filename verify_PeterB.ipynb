{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python371064bitmyenvconda9e03882772544edc80651ff5140c8c7b",
   "display_name": "Python 3.7.10 64-bit ('myenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Evaluating Bias Within Cards Dealt to Players within a Session by the International Skat Server (ISS)\n",
    "## Overview\n",
    "Personal observations by players idicated that cards dealt by the International Skat Server (ISS) were not fully random and that certain sessions had sequences of ‘good’ cards, while other sessions had sequences of ‘bad’ cards.\n",
    "\n",
    "The resulting questions is whether there is a higher occurance of high or low quality cards within a particular session than can be explained by chance alone.\n",
    "\n",
    "What are high or low quality cards? The quality of a hand in Skat is complex as it depends both on the combination of cards, the type of game that a player could chose with them, the value of that game in bidding vs the hands of other players, and the skill of the player in recognising all these factors.\n",
    "\n",
    "## Libraries Used\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as pyplot\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.multitest as multitest\n",
    "import statsmodels.api as api\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "import issgame"
   ]
  },
  {
   "source": [
    "\n",
    "## Skat Hand Quality\n",
    "An established approximation of the quality of a skat hand can be obtained by the Stegen Model, used in particular to give training skat professionals a reference for recognising which games are worth bidding for (https://www.skatfuchs.eu/SB-Kapitel3.pdf):\n",
    "\n",
    "For a normal suit game (pick highest scoring suit):\n",
    "+ 1 point per trump\n",
    "+ 1 point per jack\n",
    "+ 1 point per trump A, 10\n",
    "+ 1 point per other A, 10\n",
    "+ 0.5 points if JC JS\n",
    "+ 1.5 points if JC JS JH\n",
    "+ 0.5 points if JS JH JC\n",
    "+ 2 points if JC JS JH JC\n",
    "+ 0.5 points per missing suit\n",
    "+ (0.5 if opponent does not bid)\n",
    "\n",
    "A score of 10 or higher is considered good enough to bid.\n",
    "\n",
    "For a grand game:\n",
    "+ 1 point per jack\n",
    "+ 1 point per A, 10\n",
    "\n",
    "For grands a score of 6 is considered good enough to bid. To make this comparable to the suit score, we can inflate Grand score by 5/3\n",
    "\n",
    "Based on this we can evaluate the quality of a hand base don the total score of a hand either for a suit or a grand game, whichever is higher.\n",
    "\n",
    "Stegen does not account for null games. For the sake of this analysis does not take into account the quality of cards for a null game.\n",
    "\n",
    "## Dataset\n",
    "Two datasets are available from the ISS Server that includes over 7 million Skat games played:\n",
    "+ https://skatgame.net/iss/iss-games-04-2021.sgf.bz2\n",
    "+ https://skatgame.net/iss/iss2-games-04-2021.sgf.bz2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/iss-games-04-2021.sgf') as games_file:\n",
    "    print(games_file.readline())"
   ]
  },
  {
   "source": [
    "These datasets contain data points relevant to the analysis:\n",
    " + Players involved in a game (*P0\\[Montana\\]P1\\[vaun\\]P2\\[Ben\\]*)\n",
    " + Date and time of the game (*DT\\[2007-10-29/04:44:01/UTC\\]*)\n",
    " + Cards dealt to the Skat and players (*HT.ST.DK.HK.CT.* etc.)\n",
    "\n",
    "The datasets also contain details of the result of bidding and the resulting game, which we do not use for this analysis.\n",
    "\n",
    "## Extraction and conversion\n",
    "The datasets use a unique format and contain more information than required, so we extract only the relevant fields from both sets and write them to a clean datasets."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "input_filenames = ['data/iss-games-04-2021.sgf', 'data/iss2-games-04-2021.sgf']\n",
    "output_filename = 'data/iss_all_games.csv'\n",
    "\n",
    "issgame.extract_data(input_filenames, output_filename)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "This reduces the data to only the required fields by calculating a score for each hand of each player:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_filename) as games_file:\n",
    "    line = games_file.readline()\n",
    "    print(line)\n",
    "    id_tag, session, player, position, hand_score = line.split(',')\n",
    "    print('ID:', id_tag, '\\nSession:', session, '\\nPlayer:', player, '\\nPosition:', position, '\\nHand Score:', hand_score)"
   ]
  },
  {
   "source": [
    "Since we are particularly interested in the sessions played by player PeterB we further summarise those sessions into a single file:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filename = output_filename\n",
    "issgame.extract_sessions(input_filename, 'PeterB')\n",
    "\n",
    "with open(input_filename[:-4] + '_PeterB.csv') as games_file:\n",
    "    for i in range(4):\n",
    "        line = games_file.readline()\n",
    "        print(line)\n",
    "\n",
    "    player, session, = line.split(',')[:2]\n",
    "    hand_scores = line.split(',')[2:]\n",
    "    hand_scores[-1] = hand_scores[-1][:-1]\n",
    "    print('\\nPlayer:', player, '\\nSession:', session, '\\nHand scores:', hand_scores)\n"
   ]
  },
  {
   "source": [
    "## PeterB Session Means Compared\n",
    "If the hands in a session were particularly good or poor this would be reflected in a high or low mean hand score of that session. To assess whether hands dealt to PeterB in certain sessions, we compare the mean hand score of that session to the mean hand score of all hands played from position 0 on the iss server.\n",
    "\n",
    "We first load all scores for hands played by PeterB, excluding those sessions with less than 10 hands, since a meaningful comparison cannot be made with such few hands.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "player_filename = 'data/iss_all_games_PeterB.csv'\n",
    "player_hands = issgame.load_sessions(player_filename, 'PeterB')\n",
    "\n",
    "player_sessions = []\n",
    "player_means = []\n",
    "session_n = []\n",
    "session_count = 0\n",
    "\n",
    "for session in player_hands['PeterB']:\n",
    "    # only consider sessions with 10 or more games\n",
    "    if len(player_hands['PeterB'][session]) >= 10:\n",
    "\n",
    "        player_means.append(numpy.mean(player_hands['PeterB'][session]))\n",
    "        player_sessions.append(session_count)\n",
    "        session_count += 1\n",
    "        session_n.append(len(player_hands['PeterB'][session]))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "We then load all scores for hands played by the player in position 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hands_filename = 'data/iss_all_games.csv'\n",
    "all_hands = issgame.load_hands(input_filename, 1)"
   ]
  },
  {
   "source": [
    "Our default hypothesis that we are atempting to reject is:\n",
    "+ H0: The mean score of the session is the same as the mean score of overall sample.\n",
    "\n",
    "So the alternate hypothesis that we can accept, if H0 can be rejected is:\n",
    "+ HA: The mean score of the session is different from the mean score of the overall sample.\n",
    "\n",
    "The two populations whose mean hand score we are comparing are:\n",
    "+ All hands that could be dealt to all players on the ISS server\n",
    "+ The hands that could be dealt to PeterB in a particular session\n",
    "\n",
    "Since we do not know the standard deviation of the population and the session sample sizes are low (so we cannot assume normal distribution under CLT) we cannot use a z-test.\n",
    "\n",
    "We cannot assume that the variance of the sessions and overall sample are the same we cannot use a Student's t-test, so we use an independent two-sample Welch's t-test instead. Since we are testing for equality, we use a two-tailed measure (the session mean could be lower or higher than overall sample mean). The following additional assumptions must be met for this test:\n",
    "\n",
    "1. The data should be sampled independently \n",
    "a) Technically the scores of all hands includes a small number of scores of a particular sessions hands. However, since the sample size of the scores of all hands is several million, this should have no effect and can be neglected.\n",
    "\n",
    "2. The means of the two populations being compared should follow normal distributions.\n",
    "\n",
    "A Q-Q plot of a subsample of all hand scores does not appear to be fully normal:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hands_sample = []\n",
    "for i in range(100000):\n",
    "    all_hands_sample.append(random.choice(all_hands))\n",
    "\n",
    "all_hands_sample = numpy.array(all_hands_sample)\n",
    "\n",
    "api.qqplot(all_hands_sample, line='s')\n",
    "pyplot.show()"
   ]
  },
  {
   "source": [
    "Applying a square root transformation to the data corrects for this:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hands_sample_sqrt = numpy.sqrt(all_hands_sample)\n",
    "\n",
    "api.qqplot(all_hands_sample_sqrt, line='s')\n",
    "pyplot.show()"
   ]
  },
  {
   "source": [
    "In order to fulfill the requirement of normality, we transform (by taking the square root) both the dataset of all hands and the dataset of PeterB's sessions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hands = numpy.sqrt(all_hands)\n",
    "for session in player_hands['PeterB']:\n",
    "    player_hands['PeterB'][session] = numpy.sqrt(player_hands['PeterB'][session])"
   ]
  },
  {
   "source": [
    "A repeat of the subsample Q-Q plot for scores of all hands now shows a normal distribution:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hands_sample = []\n",
    "for i in range(100000):\n",
    "    all_hands_sample.append(random.choice(all_hands))\n",
    "\n",
    "all_hands_sample = numpy.array(all_hands_sample)\n",
    "\n",
    "api.qqplot(all_hands_sample, line='s')\n",
    "pyplot.show()"
   ]
  },
  {
   "source": [
    "For the sessions, since the sample sizes are smaller:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(session_n)"
   ]
  },
  {
   "source": [
    "\n",
    "A Shapiro-Wilk test can be used to test whether the data was drawn from a normal distribution. We perform this test at the 5% confidence level. Since we are testing the same hypothesis (that the overall population of hand scores dealt to PeterB is normal) multiple times, we use the Holm-Bonferroni method to ensure a family-wise error rate of less than 5%."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shwi_ps = []\n",
    "for session in player_hands['PeterB']:\n",
    "    # only consider sessions with 10 or more games\n",
    "    if len(player_hands['PeterB'][session]) >= 10:\n",
    "        #store p value of Shapiro-Wilk test for each session\n",
    "        shwi_ps.append(stats.shapiro(numpy.array(player_hands['PeterB'][session]))[1])\n",
    "\n",
    "# sort the p values\n",
    "shwi_ps.sort()\n",
    "\n",
    "shwi_multi = multitest.multipletests(shwi_ps, alpha=0.05, method='holm', is_sorted=True)\n",
    "print(\"Result\", \"P\", \"Corr. P\", \"Threshhold\")\n",
    "for i in range(len(shwi_multi[0])):\n",
    "    print(shwi_multi[0][i], format(round(shwi_ps[i], 3), '.3f'), format(round(shwi_multi[1][i],3),'.3f'), 0.050)\n"
   ]
  },
  {
   "source": [
    "We fail to reject the default hypothesis that the population from which the samples were drawn in normally distributed.\n",
    "\n",
    "Since both the individual session samples and the overall hand score sample show a normal distribution we can proceed with Welch's t-test. Once again, since we are performing multiple tests of the same hypothesis, we apply a Holm-Bonferroni correction.\n",
    "\n",
    "Since the impact of a type I error is high (unfairly accusing ISS of unfair shuffling), but the sample size within individual sessions is small, we select a 5% significance level.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest = []\n",
    "\n",
    "for session in player_hands['PeterB']:\n",
    "    # only consider sessions with 10 or more games\n",
    "    if len(player_hands['PeterB'][session]) >= 10:\n",
    "      \n",
    "        # store p-value of Welch's t-test of difference in mean score between\n",
    "        # this session and all hands in the datasets\n",
    "        ttest.append(stats.ttest_ind(player_hands['PeterB'][session], all_hands, equal_var = False)[1])\n",
    "\n",
    "# sort the p values\n",
    "ttest.sort()\n",
    "\n",
    "ttest_multi = multitest.multipletests(ttest, alpha=0.05, method='holm', is_sorted=True)\n",
    "print(\"Result\", \"P\", \"Corr. P\", \"Threshhold\")\n",
    "for i in range(len(ttest_multi[0])):\n",
    "    print(ttest_multi[0][i], format(round(ttest[i], 3), '.3f'), format(round(ttest_multi[1][i],3),'.3f'), 0.050)"
   ]
  },
  {
   "source": [
    "## Conclusion\n",
    "We fail to reject the default hypothesis and can conclude that we have found no evidence that the means of the scores of hands dealt to PeterB are different from the means of the scores of all hands dealt by the ISS. Thus there is no evidence that the quality of cards within a particular session differs from the others by more than could by expected due to random chance.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}